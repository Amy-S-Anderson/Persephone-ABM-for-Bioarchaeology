

library(jsonlite)
library(data.table)
library(dplyr)
library(survival)
library(foreach)
library(doParallel)


# -------------------------
# Function to create a list of the default parameters that are (likely) to remain stable across model runs.
# -------------------------

get_default_params = function() {
  params = list()
  params["cohort_size"] = 1000
  params["lesion_formation_rate"] = 0.05
  params["formation_window_opens"] = 0
  params["formation_window_closes"] = 10
  params[["mortality_regime"]] = CoaleDemenyWestF5
  params["mortality_risk_type"] = "proportional"
  params["relative_mortality_risk"] = 1
  return(params)
}



params = get_default_params()

# -------------------------
# Function to generate root output directory name of folder in which to store data produced from a single set of model parameter values.
# -------------------------
generate_output_directory <- function(params) {
  mortality_regime_number <- gregexpr("[0-9]+", params[["mortality_regime"]]$name)
  mortality_regime_abbrev <- paste0("CDW", regmatches(params[["mortality_regime"]]$name, mortality_regime_number))
  paste0(here::here("Known Unknowns", "sim_data", paste0("relative_mortality_risk=", params[["relative_mortality_risk"]]), mortality_regime_abbrev))
}


# -------------------------
# This is a prototype of a more generalizable version of the function above. 
## *Note* If you are planning to sweep over a different set of variables, you will either want to change the hard-coded directory organization in the function above, or implement this one below. ##

# generate_output_directory <- function(base_dir = here::here("sim_data"), params, rep = NULL) {
#   # params should be a *named list* of parameter values, e.g.:
#   # list(relative_mortality_risk = 2, mortality_regime = "CDW5", lesion_formation_rate = 0.01)
#   
#   # Convert params into folder names of the form "param=value"
#   param_dirs <- purrr::imap(params, function(val, name) {
#     paste0(name, "=", val)
#   })
#   
#   # Build full path
#   output_dir <- file.path(base_dir, param_dirs)
#   
#   # If a rep number is supplied, add a final directory
#   if (!is.null(rep)) {
#     output_dir <- file.path(output_dir, paste0("rep_", rep))
#   }
#   
#   # Ensure directory exists
#   if (!dir.exists(output_dir)) {
#     dir.create(output_dir, recursive = TRUE)
#   }
#   
#   return(output_dir)
# }
# -------------------------





# --------------------------------------------------------------------------------
# --------------------------------------------------------------------------------
#### SWEEP FUNCTIONS ####


# -------------------------
#### Functions to run the model and save model parameters and simulated data ####
# -------------------------

### Run the model a single time, creating a named output directory and a generating and saving a random seed.
# This function creates an 'output directory' folder and inside it, it saves
# the random seed (.csv file)
# the list of parameters used in the model (.json file)
# the data frame of imaginary people and their language data generated by the model (.csv file)
run_model_single = function(params, output_directory, seed = NA) {
  
  #Create a uniquely named output directory to store the output from this model run. 
  if (dir.exists(output_directory)) {
    print("Warning: output directory already exists! Skipping simulation to avoid overwriting data.")
    return()
  } else {
    dir.create(output_directory, recursive=TRUE)
  }
  
  #If no seed is set, set a unique random seed
  if (is.na(seed)) {
    seed = as.numeric(format(Sys.time(), "%OS6"))*1000000 #choose milliseconds of current time as seed
  }
  set.seed(seed)
  # in the output directory for this model run, keep a record of the random seed used so that the exact output of this run can be replicated. 
  write(seed, file = file.path(output_directory, "seed.csv"))
  
  
  #Write input parameters to output_directory
  write(toJSON(params, pretty=TRUE), file=file.path(output_directory, "params_used.json"))
  
  #Run model
  output = do.call(Simulate_Cemetery, params)
  
  #Write model output
  write.csv(output$individual_outcomes, file=file.path(output_directory, "sim_cemetery.csv"), row.names=FALSE)
  write.csv(output$survivors, file=file.path(output_directory, "sim_survivors.csv"), row.names=FALSE)
  
  
  #For convenience, also return output here
  return(output)
}




# -------------------------
### Function to run and save a specified number of repeated model runs that use identical parameter values.
# -------------------------

# User designates the root output directory, parameter values, and the number of runs (numreps).
# Each run will be saved in its own named folder, which will contain the files created by run_model_single() described above
run_model_reps = function(params, root_output_directory, numreps=10) {
  for (rep in 1:numreps) {
    output_directory = file.path(root_output_directory, paste0("rep=", rep))
    run_model_single(params, output_directory)
  }
}




# -------------------------
# The workhorse function to iterate and save model runs across different sets of parameter values
# -------------------------

run_model_sweep <- function(base_params, root_output_directory,
                            target_param, target_param_values,
                            numreps = 10) {
  
  # Run sweeps for each parameter value
  for (val in target_param_values) {
    param_set_output_directory <- file.path(
      root_output_directory,
      paste0(target_param, "=", val)
    )
    
    params <- copy(base_params)
    params[[target_param]] <- val
    
    run_model_reps(params, param_set_output_directory, numreps = numreps)
  }
  
  # Save metadata about the sweep 
  sweep_data <- list(
    target_param = target_param,
    target_param_values = target_param_values,
    numreps = numreps
  )
  
  write(toJSON(sweep_data, pretty = TRUE),
        file = file.path(root_output_directory, "sweep_data.json"))
  
  # -----------------------------
  # Combine all sim_cemetery.csv outputs into a single data frame
  # -----------------------------
  all_runs <- lapply(target_param_values, function(val) {
    param_dir <- file.path(root_output_directory, paste0(target_param, "=", val))
    rep_dirs <- list.dirs(param_dir, recursive = FALSE, full.names = TRUE)
    
    rep_dfs <- lapply(seq_along(rep_dirs), function(rep_idx) {
      csv_file <- file.path(rep_dirs[rep_idx], "sim_cemetery.csv")
      if (file.exists(csv_file)) {
        df <- readr::read_csv(csv_file, show_col_types = FALSE)
        df[[target_param]] <- val
        df$rep <- rep_idx
        df$mortality_regime <- base_params[["mortality_regime"]]$name
        return(df)
      } else {
        warning(paste("Missing file:", csv_file))
        return(NULL)
      }
    })
    
    dplyr::bind_rows(Filter(Negate(is.null), rep_dfs))
  })
  
  combined_df <- dplyr::bind_rows(all_runs)
  
  return(combined_df)
}


# -------------------------
# A wrapper around read_model_sweep() that sets up the parameters of this particular experiment. 
# -------------------------
run_sweep <- function(mortality_regime, lesion_rates, reps, rmr) {
  params <- get_default_params()
  params[["mortality_regime"]] <- mortality_regime
  params[["relative_mortality_risk"]] <- rmr
  
  out_dir <- generate_output_directory(params)
  
  run_model_sweep(
    base_params = params,
    root_output_directory = out_dir,
    target_param = "lesion_formation_rate",   # could be swapped for anything
    target_param_values = lesion_rates,
    numreps = reps
  )
}






# -------------------------
#### Functions to read in saved data from an already-run sweep ####
# -------------------------

### Read in the simulated data. This creates a nested list. 
read_model_sweep <- function(root_output_directory, target_param, target_param_values, data_file = "sim_cemetery.csv") {
  sweep_results <- list()
  
  # Define the expected columns for sim_cemetery.csv
  # ðŸ‘‰ Update this list if your schema changes
  required_cols <- c("Age", "Lesion")
  
  for (param_value in target_param_values) {
    param_dir <- file.path(root_output_directory,
                           paste0(target_param, "=", param_value))
    
    rep_dirs <- list.dirs(param_dir, recursive = FALSE, full.names = TRUE)
    
    rep_outputs <- lapply(seq_along(rep_dirs), function(i) {
      rep_dir <- rep_dirs[i]
      output_file <- file.path(rep_dir, data_file)
      
      if (file.exists(output_file)) {
        df <- readr::read_csv(output_file, show_col_types = FALSE)
        
        # Add any missing columns with NA
        missing_cols <- setdiff(required_cols, names(df))
        if (length(missing_cols) > 0) {
          for (col in missing_cols) {
            df[[col]] <- NA
          }
        }
        
        # Reorder columns to match schema
        df <- df[, union(required_cols, names(df))]
        
        # Add replicate index
        df$rep <- i
        
        return(df)
      } else {
        message("File missing: ", output_file)
        return(NULL)
      }
    })
    
    # Store results for this parameter value
    sweep_results[[paste0(target_param, "=", param_value)]] <- rep_outputs
  }
  
  return(sweep_results)
}



# -------------------------
### Wrapper around read_model_sweep
# -------------------------
read_sweep <- function(mortality_regime, lesion_rates, reps, rmr) {
  params <- get_default_params()
  params[["mortality_regime"]] <- mortality_regime
  params[["relative_mortality_risk"]] <- rmr
  
  out_dir <- generate_output_directory(params)
  
  sweep_results <- read_model_sweep(
    root_output_directory = out_dir,
    target_param = "lesion_formation_rate",
    target_param_values = lesion_rates
  )
  
  # Flatten the nested list
  all_reps <- lapply(seq_along(sweep_results), function(i) {
    rep_list <- sweep_results[[i]]
    
    # Remove NULL entries
    rep_list <- Filter(Negate(is.null), rep_list)
    if (length(rep_list) == 0) return(NULL)
    
    # Extract parameter value from sweep_results names
    param_name <- names(sweep_results)[i]
    lesion_value <- as.numeric(gsub("lesion_formation_rate=", "", param_name))
    
    # Add the lesion_formation_rate column to each replicate
    rep_list <- lapply(rep_list, function(df) {
      df$lesion_formation_rate <- lesion_value
      df
    })
    
    # Bind all reps for this parameter
    bind_rows(rep_list)
  })
  
  # Bind all parameter values
  sweep_df <- bind_rows(Filter(Negate(is.null), all_reps))
  
  # Annotate with mortality regime
  sweep_df$mortality <- paste0("CDW",
                               regmatches(mortality_regime$name,
                                          gregexpr("[0-9]+", mortality_regime$name))[[1]])
  
  return(sweep_df)
}





# -------------------------
##### Function to Run a Survival Analysis on each run of the model ####
# This function is used in both the main analysis and the sensitivity analysis. 
# It returns a list of two items: 
#    1) the survival data for plotting a survival curve for each run. 
#    2) the results of a log-rank test for each run. 
# it uses parallel processing for a faster run time, since it is designed to run survival analysis on a huge number of data sets. 
# -------------------------

run_survival_analysis <- function(sweep_data, parallel = TRUE, workers = NULL) {
  # Ensure Dead column exists
  sweep_data$Dead <- 1
  
  # Split data into groups once (avoids repeated filter calls in loop)
  grouped_data <- sweep_data %>%
    group_by(mortality, lesion_formation_rate, rep) %>%
    group_split()
  
  # Set up parallel backend
  if (parallel) {
    if (is.null(workers)) workers <- parallel::detectCores() - 1
    cl <- makeCluster(workers)
    registerDoParallel(cl)
  }
  
  # Parallel loop
  results <- foreach(d = grouped_data,
                     .packages = c("dplyr", "survival")) %dopar% {
                       
                       combo <- d[1, c("mortality", "lesion_formation_rate", "rep"), drop = FALSE]
                       
                       # Skip if columns are missing
                       if (!all(c("Age", "Dead", "Lesion") %in% names(d))) {
                         return(NULL)
                       }
                       
                       # Survival object + model
                       surv_obj <- Surv(time = d$Age, event = d$Dead)
                       fit <- survfit(surv_obj ~ Lesion, data = d)
                       
                       surv_summary <- summary(fit)
                       
                       surv_df <- data.frame(
                         time = surv_summary$time,
                         survival = surv_summary$surv,
                         group = as.character(surv_summary$strata),
                         mortality = combo$mortality,
                         lesion_formation_rate = combo$lesion_formation_rate,
                         rep = combo$rep
                       )
                       
                       # Log-rank test
                       logrank_test <- survdiff(surv_obj ~ Lesion, data = d)
                       p_value <- 1 - pchisq(logrank_test$chisq, df = length(logrank_test$n) - 1)
                       
                       list(
                         survival_data = surv_df,
                         logrank_results = data.frame(
                           mortality = combo$mortality,
                           lesion_formation_rate = combo$lesion_formation_rate,
                           rep = combo$rep,
                           p_value = p_value
                         )
                       )
                     }
  
  # Stop parallel backend
  if (parallel) stopCluster(cl)
  
  # Clean results
  results <- Filter(Negate(is.null), results)
  
  # Bind results
  survival_data <- bind_rows(lapply(results, `[[`, "survival_data"))
  logrank_results <- bind_rows(lapply(results, `[[`, "logrank_results"))
  
  return(list(
    survival_data = survival_data,
    logrank_results = logrank_results
  ))
}



